y_name <- as.character(form)[2]
y <- matrix(assessment(fold)[, y_name], ncol = 1)
predict_y <- suppressWarnings(model.matrix(form, assessment(fold)) %*% fit$coefficients)
as.vector(mean((y - predict_y)^2))
}}
#})
rd <- tibble(lambda = lambdas,
median = map_dbl(resids, median),
mean = map_dbl(resids, mean),
sd = map_dbl(resids, sd))
# the best data is when the mean error is the smallest
opt_lambda<- lambdas[which(rd$mean == min(rd$mean))]
final <- ridge_regression(form, dataframe, opt_lambda)
return(list(coefficients = final$coefficients, lambda = opt_lambda, for_plot=list(data=rd, x=rd$lambda[1:(opt_lambda/0.0005*3), y=rd$mean)))
}
optimize_lambda <- function(form,dataframe){
set.seed(12345)
# according to class notes
folds = vfold_cv(dataframe)
lambdas <- seq(0, 1, by=0.0005)
# use 10-fold to calculate the out-of-sample MSE
# and find the optimized lambda
#system.time({
resids <- foreach(i = seq_along(lambdas)) %dopar% {
foreach(fold = folds$splits, .combine = c) %do% {
fit <- ridge_regression(form, analysis(fold), lambdas[i])
y_name <- as.character(form)[2]
y <- matrix(assessment(fold)[, y_name], ncol = 1)
predict_y <- suppressWarnings(model.matrix(form, assessment(fold)) %*% fit$coefficients)
as.vector(mean((y - predict_y)^2))
}}
#})
rd <- tibble(lambda = lambdas,
median = map_dbl(resids, median),
mean = map_dbl(resids, mean),
sd = map_dbl(resids, sd))
# the best data is when the mean error is the smallest
opt_lambda<- lambdas[which(rd$mean == min(rd$mean))]
final <- ridge_regression(form, dataframe, opt_lambda)
return(list(coefficients = final$coefficients, lambda = opt_lambda, for_plot=list(data=rd, x=rd$lambda[1:(opt_lambda/0.0005*3)], y=rd$mean)))
}
fit_optimize_lambda <- optimize_lambda(Sepal.Length  ~ ., iris[,-5])
ggplot(fit_optimize_lambda$for_plot$rd, fit_optimize_lambda$for_plot$x, fit_optimize_lambda$for_plot$y)
ggplot(fit_optimize_lambda$for_plot$rd, aes(fit_optimize_lambda$for_plot$x, fit_optimize_lambda$for_plot$y))+geom_line()
ggplot(fit_optimize_lambda$for_plot$rd, aes(lambda= fit_optimize_lambda$for_plot$x, mean = fit_optimize_lambda$for_plot$y))+geom_line()
fit_optimize_lambda$for_plot$x
fit_optimize_lambda$for_plot$y
ggplot(rd, aes(x=rd$lambda[1:(opt_lambda/0.0005*3)], y=rd$mean[1:(opt_lambda/0.0005*3)]))
ggplot(rd, aes(x=lambda[1:(opt_lambda/0.0005*3)], y=mean[1:(opt_lambda/0.0005*3)]))
ggplot(rd, aes(x=lambda[1:(opt_lambda/0.0005*3)], y=mean[1:(opt_lambda/0.0005*3)]))
ggplot(rd, aes(x=lambda[1:(opt_lambda/0.0005*3)], y=mean[1:(opt_lambda/0.0005*3)]))+geom_line()
ggplot(rd, aes(x=lambda[1:(opt_lambda/0.0005*3)], y=mean[1:(opt_lambda/0.0005*3)]))+geom_line()
View(rd)
lambda[1:(opt_lambda/0.0005*3)]
rd$mean[1:(opt_lambda/0.0005*3)]
ggplot(rd, aes(x=lambda[1:(opt_lambda/0.0005*3)], y=mean[1:(opt_lambda/0.0005*3)])) + geom_line()
ggplot(rd1, aes(x=lambda, y=mean)) + geom_line()
rd1 <- rd[[1:(opt_lambda/0.0005*3)],]
ggplot(rd1, aes(x=lambda, y=mean)) + geom_line()
rd1 <- rd[1:(opt_lambda/0.0005*3),]
ggplot(rd1, aes(x=lambda, y=mean)) + geom_line()
optimize_lambda <- function(form,dataframe){
set.seed(12345)
# according to class notes
folds = vfold_cv(dataframe)
lambdas <- seq(0, 1, by=0.0005)
# use 10-fold to calculate the out-of-sample MSE
# and find the optimized lambda
#system.time({
resids <- foreach(i = seq_along(lambdas)) %dopar% {
foreach(fold = folds$splits, .combine = c) %do% {
fit <- ridge_regression(form, analysis(fold), lambdas[i])
y_name <- as.character(form)[2]
y <- matrix(assessment(fold)[, y_name], ncol = 1)
predict_y <- suppressWarnings(model.matrix(form, assessment(fold)) %*% fit$coefficients)
as.vector(mean((y - predict_y)^2))
}}
#})
rd <- tibble(lambda = lambdas,
median = map_dbl(resids, median),
mean = map_dbl(resids, mean),
sd = map_dbl(resids, sd))
# the best data is when the mean error is the smallest
opt_lambda<- lambdas[which(rd$mean == min(rd$mean))]
final <- ridge_regression(form, dataframe, opt_lambda)
rd1 <- rd[1:(opt_lambda/0.0005*3),]
plot <- ggplot(rd1, aes(x=lambda, y=mean)) + geom_line()
return(list(coefficients = final$coefficients, lambda = opt_lambda, for_plot=rd1, plot = plot))
}
fit_optimize_lambda <- optimize_lambda(Sepal.Length  ~ ., iris[,-5])
fit_optimize_lambda$plot
fit_optimize_lambda$lambda
#' @title Use gradient descent that calculates the loss
#' based on the out-of-sample accuracy
#' @description This function will apply gradient descent
#' to a dataset and return the coefficients and out-of-sample MSE.
#' This method will devide the imput dataset into two parts;
#' 80% as training and 20% as test dataset. It uses the 20% to calcualte
#' out of sample prediction error.
#' @param y         vector of the dependent variable
#' @param X         data frame or matrix of all the independent variables (all the elements should be numetric)
#' @param epsilon   optional; default as 0.0001, difference to determine the convergence
#' @param eta       learning rate
#' @param iters     maximum number of iterations
#' @examples
#' data(iris)
#' gradient_descent_oos(iris[,1], iris[,c(2,3,4)])
#' @export
gradient_descent_oos <- function(y,X,epsilon=0.0001,lrate=2, iters=1e5){
set.seed(12345)
# split X into training and test dataset by a 8-2 split
sp <- sort(sample(nrow(X), floor(nrow(X)*.8)))
trainX <- X[sp, ]
trainy <- y[sp]
testX <- X[-sp, ]
testy <- y[-sp]
# use the function previously built to calculate the gradient descent coefficients
coeff <- gradient_descent(trainy,trainX,epsilon,lrate,iters)$coefficients
# Calculate the out of sample MSE
intercept<-rep(1,length(testy))
testX <- as.matrix(data.frame(intercept,testX))
predy <- testX %*% coeff
MSE <- mean((testy - predy)^2)
return(list(coefficients=coeff, Out_Of_Sample_MSE = MSE))
}
View(gradient_descent_oos)
function(y,X,epsilon=0.0001,lrate=2, iters=1e5){
set.seed(12345)
# split X into training and test dataset by a 8-2 split
sp <- sort(sample(nrow(X), floor(nrow(X)*.8)))
trainX <- X[sp, ]
trainy <- y[sp]
testX <- X[-sp, ]
testy <- y[-sp]
# use the function previously built to calculate the gradient descent coefficients
coeff <- gradient_descent(trainy,trainX,epsilon,lrate,iters)$coefficients
# Calculate the out of sample MSE
intercept<-rep(1,length(testy))
testX <- as.matrix(data.frame(intercept,testX))
predy <- testX %*% coeff
MSE <- mean((testy - predy)^2)
return(list(coefficients=coeff, Out_Of_Sample_MSE = MSE))
}
View(gradient_descent_oos)
library(bis557)
mod <- lm(Sepal.Length ~ ., iris[,-5])
ise <- mean(mod$residuals^2)
ose <- gradient_descent_oos(iris[,1], iris[,c(2,3,4)])$Out_Of_Sample_MSE
ise < ose
paste("In sample error is:",ise)
paste("Out sample error is:", ose)
data("iris")
# create a colinear variable
iris$Petal.Length2 <- iris$Petal.Length * 2 + 4
fit_ridge_regression <- ridge_regression(Sepal.Length  ~ ., iris[,-5], 0.01)
fit_lm <- lm(Sepal.Length  ~ ., iris[,-5])
fit_ridge_regression
fit_lm
data(iris)
fit_optimize_lambda <- optimize_lambda(Sepal.Length  ~ ., iris[,-5])
fit_optimize_lambda$plot
fit_optimize_lambda$lambda
document()
library(devtools)
document()
rm(list = c("gradient_descent_oos", "optimize_lambda", "ridge_regression"))
document()
document()
#' @title Optimize ridge parameter lambda
#' @description This function optimizes the ridge parameter lambda and output
#' the coefficients and chosen lambda
#' @param form       ridge regression formula
#' @param dataframe  data frame
#' @examples
#' data(iris)
#' optimize_lambda(Sepal.Length ~ ., iris[,-5])
#' @import rsample
#' @import doParallel
#' @import purrr
#' @import tibble
#' @export
optimize_lambda <- function(form,dataframe){
set.seed(12345)
# according to class notes
folds = vfold_cv(dataframe)
lambdas <- seq(0, 1, by=0.0005)
# use 10-fold to calculate the out-of-sample MSE
# and find the optimized lambda
#system.time({
resids <- foreach(i = seq_along(lambdas)) %dopar% {
foreach(fold = folds$splits, .combine = c) %do% {
fit <- ridge_regression(form, analysis(fold), lambdas[i])
y_name <- as.character(form)[2]
y <- matrix(assessment(fold)[, y_name], ncol = 1)
predict_y <- suppressWarnings(model.matrix(form, assessment(fold)) %*% fit$coefficients)
as.vector(mean((y - predict_y)^2))
}}
#})
rd <- tibble(lambda = lambdas,
median = map_dbl(resids, median),
mean = map_dbl(resids, mean),
sd = map_dbl(resids, sd))
# the best data is when the mean error is the smallest
opt_lambda<- lambdas[which(rd$mean == min(rd$mean))]
final <- ridge_regression(form, dataframe, opt_lambda)
rd1 <- rd[1:(opt_lambda/0.0005*3),]
plot <- ggplot(rd1, aes(x=lambda, y=mean)) + geom_line()
return(list(coefficients = final$coefficients, lambda = opt_lambda, plot = plot))
}
document()
m(list = c("optimize_lambda"))
rm(list = c("optimize_lambda"))
document()
test()
check()
document()
check()
document()
check()
document()
check()
document()
check()
check()
check()
document()
install.packages(c("mnormt", "plotrix"))
knitr::opts_chunk$set(echo = TRUE)
load("C:/Users/hchc/Desktop/sth/hwbayes/hwbayes/hw3/MVN.RData")
load("C://Users//hchc//Desktop//sth//hwbayes//hwbayes//hw3//MVN.RData")
setwd("C://Users//hchc//Desktop//sth//hwbayes//hwbayes//hw3//MVN.RData")
setwd("C:\Users\hchc\Desktop\sth\hwbayes\hwbayes\hw3\MVN.RData")
setwd("C:\Users\hchc\Desktop\sth\hwbayes\hwbayes\hw3\MVN.RData")
setwd("C:\\Users\\hchc\\Desktop\\sth\\hwbayes\\hwbayes\\hw3\\MVN.RData")
load("C:\\Users\\hchc\\Desktop\\sth\\hwbayes\\hwbayes\\hw3\\MVN.RData")
install.packages(“rjags”)
install.packages(“rjags”)
install.packages(“rjags”)
install.packages('rjags')
library(rjags)
library(rjags)
install.packages("jagsUI")
library(rjags)
library(rjags)
library(jagsUI)
library(rjags)
install.packages('rjags')
library(rjags)
library(rjags)
alpha <- c(1,1,1)
n <- 500
Y <- c(30, 110, 360)
rdirichlet(n, alpha)
install.packages("gtools")
library(gtools)
rdirichlet(n, alpha)
Dir <- rdirichlet(n, alpha)
colMeans(Dir)
mean <- alpha / sum(alpha)
colMeans(Dir)
var <- (mean * (1 - mean)) / (mean + 1)
var(Dir)
var(Dir[,1])
(mean * (1 - mean))
mean + 1
var <- (mean * (1 - mean)) / (3 + 1)
var <- (mean * (1 - mean)) / (k + 1)
k <- 3
var <- (mean * (1 - mean)) / (k + 1)
var(Dir[,1])
var(Dir[,2])
var(Dir[,3])
cov <-
cov(Dir[,1],Dir[,2])
cov(Dir[,1],Dir[,2])
cov <- -alpha[1]^2 / (sum(alpha))^2 * (sum(alpha) + 1)
cov(Dir[,1],Dir[,2])
cov <- -alpha[1]^2 / ((sum(alpha))^2 * (sum(alpha) + 1))
cov(Dir[,1],Dir[,2])
cov(Dir[,2],Dir[,3])
cov(Dir[,1],Dir[,3])
c("mean", mean)
rbind(c(" ", "p1", "p2", "p3"),c("mean", mean),c("variance", bar),c("covariance", cov))
rbind(c(" ", "p1", "p2", "p3"),c("mean", mean),c("variance", var),c("covariance", cov))
mean <- round(alpha / sum(alpha),4)
var <- round((mean * (1 - mean)) / (k + 1),4)
cov <- round(-alpha[1]^2 / ((sum(alpha))^2 * (sum(alpha) + 1)),4)
rbind(c(" ", "p1", "p2", "p3"),c("mean", mean),c("variance", var),c("covariance", cov))
colnames(result) <- c("p1", "p2", "p3")
result <- rbind(mean, var, cov)
rownames(result) <-c ("mean", "variance", "covariance")
colnames(result) <- c("p1", "p2", "p3")
result
install.packages("MCMCpack")
rdirichlet(n, alpha)
Dirich <- rdirichlet(n, alpha)
mean2 <- colMeans(Dirich)
var2 <- var(Dirich)
var2 <- var(Dirich[,1])
var2 <- var(Dirich[,1],Dirich[,2])
var2 <- c(var(Dirich[,1]),Dirich[,2],Dirich[,3])
var2 <- c(var(Dirich[,1]),var(Dirich[,2]),var(Dirich[,3]))
cov2 <- c(cov(Dirich[,1],Dirich[,2]))
cov2 <- c(cov(Dirich[,1],Dirich[,2]),
cov(Dirich[,2],Dirich[,3]),
cov(Dirich[,1],Dirich[,3]))
result2 <- rbind(mean2, var2, cov2)
rownames(result2) <-c ("mean_sim", "variance_sim", "covariance_sim")
colnames(result2) <- c("p1", "p2", "p3")
result2
std.error()
library(plotrix)
std.error()
?std.error
sim.stderr<-apply(Dirich,std.error)
,c(1,2)
sim.stderr<-apply(Dirich,1,std.error)
sim.std<-apply(Dirich,2,std.error)
sim.std
var2 <- apply(Dirich, 2, var)
apply(Dirich, 2, cov)
apply(Dirich, 2, covariance)
var2 <- apply(Dirich, 2, var)
cov2 <- c(cov(Dirich[,1],Dirich[,2]),
cov(Dirich[,2],Dirich[,3]),
cov(Dirich[,1],Dirich[,3]))
result2 <- rbind(mean2, var2, cov2)
rownames(result2) <-c ("mean_sim", "variance_sim", "covariance_sim")
colnames(result2) <- c("p1", "p2", "p3")
result2
#first invert the inverse of cov matrix
newp <- sqrt(Dirich[,1]^Dirich[,2]/Dirich[,3])
mean3 <- mean(newp)
mean3
var3 <- var(newp)
var3
t<-qt(0.975,sim-1)
t<-qt(0.975,1)
?qt
## Confidence Interval For a Sample
t<-qt(0.975,newp)
newp
## Confidence Interval For a Sample
t<-qt(0.975,newp-1)
## Confidence Interval For a Sample
t<-qt(0.975,newp)
low.rg<-sim.cov.mean-t*sqrt(sim.cov.var/(sim-1))/sqrt(sim)
## Confidence Interval For a Sample
t<-qt(0.975,100)
## Confidence Interval For a Sample
t<-qt(0.975,1000)
## Confidence Interval For a Sample
t<-qt(0.975,n)
low.rg<-mean3-t*sqrt(var3/(newp))/sqrt(newp)
low.rg
low.rg<-mean3-t*sqrt(var3/n)/sqrt(n)
low.rg
hi.rg<-mean3+t*sqrt(var3/n)/sqrt(n)
hi.rg
t
mean3
hi.rg<-mean3+t*sqrt(newp*(1-newp))/sqrt(n)
hi.rg
t<-qt(0.975,n)
low95<-mean3-t*sqrt(var3)/sqrt(n)
low95
hi95<-mean3+t*sqrt(var3)/sqrt(n)
hi95
min(newp)
max(newp)
hist(newp)
hi95
hist(newp)
alpha <- Y + c(1,1,1)
mean <- round(alpha / sum(alpha),4)
var <- round((mean * (1 - mean)) / (k + 1),4)
cov <- round(-alpha[1]^2 / ((sum(alpha))^2 * (sum(alpha) + 1)),4)
result <- rbind(mean, var, cov)
rownames(result) <-c ("mean", "variance", "covariance")
colnames(result) <- c("p1", "p2", "p3")
result
library(MCMCpack)
Dirich <- rdirichlet(n, alpha)
mean2 <- colMeans(Dirich)
var2 <- apply(Dirich, 2, var)
cov2 <- c(cov(Dirich[,1],Dirich[,2]),
cov(Dirich[,2],Dirich[,3]),
cov(Dirich[,1],Dirich[,3]))
result2 <- rbind(mean2, var2, cov2)
rownames(result2) <-c ("mean_sim", "variance_sim", "covariance_sim")
colnames(result2) <- c("p1", "p2", "p3")
result2
library(MCMCpack)
Dirich <- rdirichlet(n, alpha)
mean2 <- colMeans(Dirich)
var2 <- apply(Dirich, 2, var)
cov2 <- c(cov(Dirich[,1],Dirich[,2]),
cov(Dirich[,2],Dirich[,3]),
cov(Dirich[,1],Dirich[,3]))
result2 <- rbind(mean2, var2, cov2)
rownames(result2) <-c ("mean_sim", "variance_sim", "covariance_sim")
colnames(result2) <- c("p1", "p2", "p3")
result2
library(MCMCpack)
Dirich <- rdirichlet(n, alpha)
mean2 <- round(colMeans(Dirich), 4)
var2 <- round(apply(Dirich, 2, var), 4)
cov2 <- round(c(cov(Dirich[,1],Dirich[,2]),
cov(Dirich[,2],Dirich[,3]),
cov(Dirich[,1],Dirich[,3])),4)
result2 <- rbind(mean2, var2, cov2)
rownames(result2) <-c ("mean_sim", "variance_sim", "covariance_sim")
colnames(result2) <- c("p1", "p2", "p3")
result2
mean2 <- matrix(0,100000, k)
View(mean2)
mean2 <- matrix(NA,100000, k)
var2 <- matrix(NA,100000, k)
cov2 <- matrix(NA,100000, k)
for (i in 1:range(100000)){
Dirich <- rdirichlet(n, alpha)
mean2[i,] <- colMeans(Dirich)
var2[i,] <- apply(Dirich, 2, var)
cov2[i,] <- c(cov(Dirich[,1],Dirich[,2]),
cov(Dirich[,2],Dirich[,3]),
cov(Dirich[,1],Dirich[,3]))
}
result2 <- rbind(round(colMeans(mean2),4),
round(colMeans(var2),4),
round(colMeans(cov2),4))
rownames(result2) <-c ("mean_sim", "variance_sim", "covariance_sim")
colnames(result2) <- c("p1", "p2", "p3")
result2
View(result)
View(result2)
var2 <- matrix(NA,100000, k)
cov2 <- matrix(NA,100000, k)
View(var2)
View(mean2)
for (i in 1:range(100000)){
Dirich <- rdirichlet(n, alpha)
mean2[i,] <- colMeans(Dirich)
var2[i,] <- apply(Dirich, 2, var)
cov2[i,] <- c(cov(Dirich[,1],Dirich[,2]),
cov(Dirich[,2],Dirich[,3]),
cov(Dirich[,1],Dirich[,3]))
}
result2 <- rbind(round(colMeans(mean2),4),
round(colMeans(var2),4),
round(colMeans(cov2),4))
View(var2)
rownames(result2) <-c ("mean_sim", "variance_sim", "covariance_sim")
colnames(result2) <- c("p1", "p2", "p3")
result2
apply(Dirich, 2, var)
mean <- round(alpha / sum(alpha),4)
var <- round((mean * (1 - mean)) / (k + 1),4)
cov <- round(-alpha[1]^2 / ((sum(alpha))^2 * (sum(alpha) + 1)),4)
result <- rbind(mean, var, cov)
rownames(result) <-c ("mean", "variance", "covariance")
colnames(result) <- c("p1", "p2", "p3")
result
var <- round((mean * (1 - mean)) / (sum(alpha) + 1),4)
cov <- round(-alpha[1]^2 / ((sum(alpha))^2 * (sum(alpha) + 1)),4)
result <- rbind(mean, var, cov)
rownames(result) <-c ("mean", "variance", "covariance")
colnames(result) <- c("p1", "p2", "p3")
result
cov <- round(c(-alpha[1]*alpha[2] / ((sum(alpha))^2 * (sum(alpha) + 1)),
-alpha[2]*alpha[3] / ((sum(alpha))^2 * (sum(alpha) + 1)),
-alpha[1]*alpha[3] / ((sum(alpha))^2 * (sum(alpha) + 1))),4)
result <- rbind(mean, var, cov)
rownames(result) <-c ("mean", "variance", "covariance")
colnames(result) <- c("p1", "p2", "p3")
result
sim.std <- matrix(NA,100000, k)
for (i in 1:range(100000)){
Dirich <- rdirichlet(n, alpha)
sim.std[i,] <-apply(Dirich,2,std.error)
}
colMeans(sim.std)
mean3 <- matrix(NA,100000, k)
var3 <- matrix(NA,100000, k)
low95 <- matrix(NA,100000, k)
high95 <- matrix(NA,100000, k)
for (i in 1:range(100000)){
Dirich <- rdirichlet(n, alpha)
#first invert the inverse of cov matrix
newp <- sqrt(Dirich[,1]^Dirich[,2]/Dirich[,3])
mean3[i, ] <- mean(newp)
var3[i, ] <- var(newp)
## Confidence Interval
t<-qt(0.975,n)
low95[i, ] <-mean3-t*sqrt(var3)/sqrt(n)
hi95[i, ] <-mean3+t*sqrt(var3)/sqrt(n)
}
mean3 <- rep(NA,100000)
mean3 <- rep(NA,100000)
var3 <- rep(NA,100000)
low95 <- rep(NA,100000)
high95 <- rep(NA,100000)
for (i in 1:range(100000)){
Dirich <- rdirichlet(n, alpha)
#first invert the inverse of cov matrix
newp <- sqrt(Dirich[,1]^Dirich[,2]/Dirich[,3])
mean3[i] <- mean(newp)
var3[i] <- var(newp)
## Confidence Interval
t<-qt(0.975,n)
low95[i] <-mean3-t*sqrt(var3)/sqrt(n)
hi95[i] <-mean3+t*sqrt(var3)/sqrt(n)
}
