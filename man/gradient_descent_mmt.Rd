% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gradient_descent_mmt.R
\name{gradient_descent_mmt}
\alias{gradient_descent_mmt}
\title{Use gradient descent for GLM with constant or adaptive step size}
\usage{
gradient_descent_mmt(
  y,
  X,
  family,
  update = TRUE,
  lrate = 0.001,
  iters = 1e+05,
  epsilon = 1e-08,
  change = 0.9
)
}
\arguments{
\item{y}{vector of the dependent variable}

\item{X}{data frame or matrix of all the independent variables (all the elements should be numetric)}

\item{family}{define the y distribution}

\item{update}{optional; default as TRUE (use momentum algorithm to update the step size)
set FALSE then use constant step size}

\item{lrate}{learning rate}

\item{iters}{maximum number of iterations}

\item{epsilon}{error tolerence}

\item{change}{rate of change of momentum algorithem}
}
\description{
This function implements a first-order solution for the GLM maximum likelihood problem using only gradient information.
Include both a constant step size along with an adaptive one (using momentum algorithm).
}
\examples{
data("penguins")
X = penguins[-which(is.na(penguins[,c(3,4,5,6)])),c(3,4,5,6)]
X = cbind(1,scale(X))
y = (unlist(penguins[-which(is.na(penguins[,c(3,4,5,6)])),1]))
data = cbind(X,y)
logit_multiclass(X,y)
}
