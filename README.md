# bis557

<!-- badges: start -->
[![Travis build status](https://travis-ci.com/liananan18/bis557.svg?branch=master)](https://travis-ci.com/liananan18/bis557)
[![Coverage Status](https://coveralls.io/repos/github/liananan18/bis557/badge.svg?branch=master)](https://coveralls.io/github/liananan18/bis557?branch=master)
<!-- badges: end -->

This BIS557 package contains class assignment answers, write-ups and other materials by Lian.

## Installation

You can install this {bis557} package from [Github](https://github.com/liananan18/bis557.git) with:

``` r
library(devtools)
devtools::install_github("liananan18/bis557")
```


## Dataset
load the 'lm_patho' dataset from the {bis557} package, which can be used as a tough case of linear regression. 
```{r setup}
library(bis557)
data(lm_patho)
```


## Funtions

### Linear Model
You can used a formula and a dataframe to create a linear model.The output is the estimated coefficients of the regression. I used linear algebra with matrix multiplication to build this model.
A simple example as below:
```{r}
library(bis557)
data(iris)
linear_model(Sepal.Length ~ ., iris)
```
To deal with a dataset with extreme values, I used function QR factorization with `qr.coef()` function to solve the issue.
Here is an example with extreme case:
```{r}
library(bis557)
data(lm_patho)
linear_model(y ~., lm_patho)
```
When there are factors in the dataset, you can also use the "contrasts" parameter to customize how to create the contrasts and build a linear model accordingly:
```{r}
library(bis557)
data(iris)
linear_model(Sepal.Length ~ ., iris, contrasts = list(Species = "contr.sum"))
```

### Gradient Descent
Use the gradient descent method to find the estimated coefficient.
```{r}
library(bis557)
data(iris)
gradient_descent(iris[,1], iris[,2:4])
```

--------------------------------------------------------------

### Gradient Descent Out of Sample Error
Calculate the out of sample error
```{r}
mod <- lm(Sepal.Length ~ ., iris[,-5])
ise <- mean(mod$residuals^2)
ose <- gradient_descent_oos(iris[,1], iris[,c(2,3,4)])$Out_Of_Sample_MSE
ise < ose

paste("In sample error is:",ise)
paste("Out sample error is:", ose)
```
Compare to the OLS model, the out of sample error is usually greater than the in sample error. 


### Ridge Regression
A ridge regression which takes in a lambda and can deal with colinear variables
```{r}
data("iris")
  
# create a colinear variable
iris$Petal.Length2 <- iris$Petal.Length * 2 + 4
  
fit_ridge_regression <- ridge_regression(Sepal.Length  ~ ., iris[,-5], 0.01)
  
fit_lm <- lm(Sepal.Length  ~ ., iris[,-5])

fit_ridge_regression
fit_lm
```

### Optimize Lambda in Ridge Regression
Pick an optimal lambda for a redge regression, which has the smallest error
```{r}
data(iris)
fit_optimize_lambda <- optimize_lambda(Sepal.Length  ~ ., iris[,-5])

fit_optimize_lambda$plot
fit_optimize_lambda$lambda
```

--------------------------------------------------------------

### GLM with Gradient Descent and Momentum Adaptive Update for Step Sizes
Used frist-order gradient descent with momentum adaptive update. 
Results are similar to the ones generated by glm(). 
```{r}
set.seed(10)
# Momentum Algorithm
X <- cbind(rep(1,100),matrix(rnorm(1000),200))
##poisson simulation
beta <- c(1, 0.1, 0.2, 0.1, 0.3, -1)
y <- rpois(nrow(X), exp(X%*%beta))
data <- as.data.frame(cbind(y,X[,-1]))
glm(y~.,data,family = poisson)
# with adaptive step size update
gradient_descent_mmt(y,X,family = poisson(link = "log"),update = T)
# constant step size
gradient_descent_mmt(y,X,family = poisson(link = "log"),update = F)
```

### Classification model Generalizing Logistic Regression Accommodating More Than Two Classes

Change y into rows of binary (3 classes = 3 rows) classes and then apply a regular logistic model to each line of data. 
This method gives coefficients as a matrix, makes predictions, and calculates am error rate. 
```{r}
data("penguins")
X = penguins[-which(is.na(penguins[,c(3,4,5,6)])),c(3,4,5,6)]
X = cbind(1,scale(X))
y = (unlist(penguins[-which(is.na(penguins[,c(3,4,5,6)])),1]))
data = cbind(X,y)
logit_multiclass(X,y)
```
